---

ollama_url: "https://github.com/ollama/ollama/releases/download/v0.5.7/ollama-linux-amd64.tgz"
ollama_hash: "sha256:8d4e054bc512d53115074c19de5a7915df78180f89c014abbae4497e4a813a3c"
ollama_user: _ollama
ollama_home: /var/_ollama
ollama_user_groups: ['render', 'video']

ollama_models_downloads:
  - tinyllama  # 700MB
  # - mistral  # 4GB
  # - deepseek-r1  # 5GB
  # - phi4  # 9GB
  # - llama3.3  # 43GB

ollama_amdgpu_enable: false

ollama_env_variables_template: "default-env.j2"
ollama_env_config: []
# OLLAMA_HOST=
# OLLAMA_DEBUG=1
# https://github.com/ollama/ollama/blob/main/docs/gpu.md#overrides
# HSA_OVERRIDE_GFX_VERSION=

# This will set ollama HTTPS_PROXY
# proxy_url: http://proxy:3128

# if using GPU, need those settings
# ollama_systemd_rwpaths: /dev/kfd /dev/dri
# ollama_systemd_privatedevices: no

ollama_cgroups_restriction_enable: true

install_archives: "/var/_install"
is_container: false
